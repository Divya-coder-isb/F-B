# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bdIdHqpK-2yu8lLUDgxoZn4p_Rkf5vuW
"""

import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
import joblib
import requests
from io import BytesIO

# Function to download model or vectorizer from GitHub
def load_model(url):
    response = requests.get(url)
    response.raise_for_status()  # Check that the request was successful
    return joblib.load(BytesIO(response.content))

# Streamlit User Interface Setup
st.title('Model Fairness and Bias Evaluation Dashboard')

# Load model and vectorizer
model_url = 'https://github.com/Divya-coder-isb/F-B/blob/main/best_xgboost_model.joblib?raw=true'
vectorizer_url = 'https://github.com/Divya-coder-isb/F-B/blob/main/tfidf_vectorizer.joblib?raw=true'
model = load_model(model_url)
vectorizer = load_model(vectorizer_url)

# Sidebar for user inputs
threshold = st.sidebar.slider('Classification Threshold', 0.0, 1.0, 0.237, 0.01)
user_input = st.text_area("Enter text for toxicity prediction:")

# Function to calculate and display metrics
def display_metrics(proba, prediction):
    st.write('Probability of Toxicity:', proba)
    st.write('Prediction: Toxic' if prediction else 'Prediction: Not Toxic')

    # Assuming some placeholder values for demonstration
    accuracy = 0.95
    recall = 0.80
    precision = 0.85
    f1 = 2 * (precision * recall) / (precision + recall)

    st.write("### Model Performance Metrics")
    st.write(f"Accuracy: {accuracy:.2f}")
    st.write(f"Recall: {recall:.2f}")
    st.write(f"Precision: {precision:.2f}")
    st.write(f"F1 Score: {f1:.2f}")

# Handle prediction and visualization
if st.button('Predict'):
    transformed_input = vectorizer.transform([user_input])
    proba = model.predict_proba(transformed_input)[0, 1]
    prediction = (proba >= threshold).astype(int)
    display_metrics(proba, prediction)

# Function to visualize ROC Curve
def plot_roc_curve():
    labels = np.random.randint(0, 2, size=100)
    y_scores = np.random.rand(100)
    fpr, tpr, _ = roc_curve(labels, y_scores)
    roc_auc = auc(fpr, tpr)
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic')
    plt.legend(loc="lower right")
    plt.grid(True)
    st.pyplot(plt)

plot_roc_curve()